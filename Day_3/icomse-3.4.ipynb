{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves as an example of how to analyze a simulation trajectory using unsupervised techniques. Here, specifically, we'll be analyzing a simulation of cyclohexane conformations, simulated using quantum-espresso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this notebook, you will need to install:\n",
    "    \n",
    "- [ase](https://wiki.fysik.dtu.dk/ase/index.html)\n",
    "- [scikit-learn](https://scikit-learn.org/)\n",
    "- [scikit-matter](https://github.com/scikit-learn-contrib/scikit-matter)\n",
    "- [chemiscope](https://chemiscope.org)\n",
    "\n",
    "in addition to standard packages [numpy](https://numpy.org/) and [matplotlib](https://matplotlib.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Chemiscope widgets in Jupyter\n",
    "\n",
    "Please make sure you have jupyter extensions enabled.\n",
    "\n",
    "If at *any time* you are unable to load the chemiscope widgets in Jupyter, you can replace `chemiscope.show(` with `chemiscope.write_input('filename.json', ...` and upload the resulting file to [chemiscope.org](chemiscope.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ase skmatter chemiscope dataframe-image dscribe \n",
    "!git clone https://github.com/icomse/5th_workshop_MachineLearning.git\n",
    "\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from matplotlib import pyplot as plt\n",
    "import chemiscope\n",
    "import scipy\n",
    "\n",
    "import os\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import pandas as pd\n",
    "from pandas.plotting import table\n",
    "from ase.geometry.analysis import Analysis as asis\n",
    "from ase.neighborlist import NeighborList as NL\n",
    "from ase.neighborlist import natural_cutoffs\n",
    "import dataframe_image as dfi\n",
    "\n",
    "names = {\"C\": \"Carbon\", \"H\": \"Hydrogen\"}\n",
    "colors = {\"H\": (0.6, 0.6, 0.6), \"C\": (0.2, 0.2, 0.2)}\n",
    "os.chdir('5th_workshop_MachineLearning/Day_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data\n",
    "\n",
    "Here we read in 5 MD trajectories and place them in a concatenated list `traj`.\n",
    "\n",
    "`ranges` is storing the range of `traj` corresponding to each original file.\n",
    "`conf_idx` is storing the location of the initial conformations.\n",
    "\n",
    "`rgb_colors` is the set of colors used for each conformer, stored in rgba format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the frames from each MD simulation\n",
    "traj = []\n",
    "names = [\"chair\", \"twist-boat\", \"boat\", \"half-chair\", \"planar\"]\n",
    "rgb_colors = [\n",
    "    (0.13333333333333333, 0.47058823529411764, 0.7098039215686275),\n",
    "    (0.4588235294117647, 0.7568627450980392, 0.34901960784313724),\n",
    "    (0.803921568627451, 0.6078431372549019, 0.16862745098039217),\n",
    "    (0.803921568627451, 0.13725490196078433, 0.15294117647058825),\n",
    "    (0.4392156862745098, 0.2784313725490196, 0.611764705882353),\n",
    "]\n",
    "\n",
    "ranges = np.zeros((len(names), 2), dtype=int)\n",
    "conf_idx = np.zeros(len(names), dtype=int)\n",
    "\n",
    "for i, n in enumerate(names):\n",
    "    frames = read(f\"./datasets/cyclohexane/{n}.xyz\",\":\",)\n",
    "\n",
    "    ranges[i] = (len(traj), len(traj) + len(frames))\n",
    "    conf_idx[i] = len(traj)\n",
    "    traj = [*traj, *frames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# energies of the simulation frames, relative to the chair conformation\n",
    "energy = np.array([a.info[\"relative_energy_eV\"] for a in traj])\n",
    "\n",
    "# energies of the known conformers, relative to the chair conformation\n",
    "c_energy = np.array([traj[c].info[\"relative_energy_eV\"] for c in conf_idx])\n",
    "\n",
    "# extrema for the energies\n",
    "max_e = max(energy)\n",
    "min_e = min(energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can confirm what our analysis will tell us: \n",
    "\n",
    "- the simulation starting in the planar conformation transitions to the chair conformation\n",
    "- the simulations starting in the twist-boat, boat, and half-chair conformations ultimately get stuck in the twist formation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(6, 4))\n",
    "\n",
    "for n, c, r, rgb in zip(names, c_energy, ranges, rgb_colors):\n",
    "    ax.plot(\n",
    "        range(0, r[1] - r[0]), energy[r[0] : r[1]] - min_e, label=n, c=rgb, zorder=-1\n",
    "    )\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Simulation Timestep\")\n",
    "ax.set_ylabel(\"Energy\")\n",
    "\n",
    "ax.set_xlim([0, len(energy) // 5])\n",
    "ax.set_ylim([-0.1, 1.25 * (max_e - min_e)])\n",
    "ax.set_yticklabels([])\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('figures/Figure5/energy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP! Up until now we've just loaded some pre-computed descriptors. But now... let's do this ourself!\n",
    "\n",
    "## Let's start with the first frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = traj[0]\n",
    "\n",
    "positions = frame.positions\n",
    "positions -= positions.min(axis=0)\n",
    "order = list(sorted(range(len(frame)), key=lambda i: (-frame.numbers[i], *positions[i])))\n",
    "\n",
    "positions = np.round(positions, 3)[order].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl = NL(\n",
    "    cutoffs=np.multiply(1, natural_cutoffs(frame)),\n",
    "    bothways=True,\n",
    "    self_interaction=False,\n",
    ")\n",
    "nl.update(frame)\n",
    "a = asis(frame, nl=nl)\n",
    "angles = a.get_angles(\"C\", \"C\", \"C\", unique=True)\n",
    "angle_vals = a.get_values(angles)\n",
    "\n",
    "bonds = a.get_bonds(\"C\",\"C\", unique=True)\n",
    "bond_vals = a.get_values(bonds)\n",
    "\n",
    "# positions\n",
    "positions_table = pd.DataFrame(\n",
    "    positions,\n",
    "    index=[\n",
    "        f\"{frame.symbols[i]}{frame.numbers[:i].tolist().count(n)+1}\"\n",
    "        for i, n in enumerate(frame.numbers)\n",
    "    ],\n",
    "    columns=[r\"$x$\", r\"$y$\", r\"$z$\"],\n",
    ")\n",
    "positions_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are our _internal coordinates_\n",
    "\n",
    "### What about our bond angles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bond angles\n",
    "bond_table = pd.DataFrame(\n",
    "    np.transpose(np.round(angle_vals, 3)),\n",
    "    index=[\"C{}-C{}-C{}\".format(*np.sort(np.add(a, 1))) for a in angles[0]],\n",
    "    columns=[r\"Bond Angle ($^\\circ$)\"],\n",
    ")\n",
    "bond_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look at the distance matrix (known as the Z-matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.array(\n",
    "    [[np.linalg.norm(np.subtract(x, y)) for x in positions] for y in positions]\n",
    ")\n",
    "\n",
    "fig, (ax, cax) = plt.subplots(\n",
    "    2, 1, figsize=(4,6), gridspec_kw=dict(height_ratios=(1.0, 0.1))\n",
    ")\n",
    "p = ax.imshow(distances, cmap=\"bwr\", vmax=4.0)\n",
    "\n",
    "ax.axvline(5.5, c=\"k\", lw=2)\n",
    "ax.axhline(5.5, c=\"k\", lw=2)\n",
    "\n",
    "ax.annotate(\"C\", xy=(2.5, -0.5), xytext=(2.5, -1.0), ha=\"center\", va=\"center\")\n",
    "ax.annotate(\"C\", xy=(-0.5, 2.5), xytext=(-1.0, 2.5), ha=\"center\", va=\"center\")\n",
    "ax.annotate(\"H\", xy=(11.5, -0.5), xytext=(11.5, -1.5), ha=\"center\", va=\"center\")\n",
    "ax.annotate(\"H\", xy=(-0.5, 11.5), xytext=(-1.5, 11.5), ha=\"center\", va=\"center\")\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "plt.colorbar(\n",
    "    p, label=r\"$d, (\\AA)$\", ax=ax, cax=cax, orientation=\"horizontal\", fraction=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we know our neighborhood cutoffs, then we can make an _adjacency matrix_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjacency-matrix\n",
    "adjacency = np.array(\n",
    "    [[np.linalg.norm(np.subtract(x, y)) for x in positions] for y in positions]\n",
    ")\n",
    "adjacency[adjacency==0] = np.inf\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    1, 1, figsize=(4,4)\n",
    ")\n",
    "\n",
    "# Here we are selecting a cutoff of 1.6 Angstrom\n",
    "p = ax.imshow(adjacency<1.6, cmap=\"Greys\", vmax=1.0)\n",
    "\n",
    "ax.axvline(5.5, c=\"k\", lw=2)\n",
    "ax.axhline(5.5, c=\"k\", lw=2)\n",
    "\n",
    "ax.annotate(\"C\", xy=(2.5, -0.5), xytext=(2.5, -1.0), ha=\"center\", va=\"center\")\n",
    "ax.annotate(\"C\", xy=(-0.5, 2.5), xytext=(-1.0, 2.5), ha=\"center\", va=\"center\")\n",
    "ax.annotate(\"H\", xy=(11.5, -0.5), xytext=(11.5, -1.5), ha=\"center\", va=\"center\")\n",
    "ax.annotate(\"H\", xy=(-0.5, 11.5), xytext=(-1.5, 11.5), ha=\"center\", va=\"center\")\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the coulomb matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dscribe.descriptors import CoulombMatrix\n",
    "\n",
    "cm = CoulombMatrix(n_atoms_max=18)\n",
    "pd.DataFrame(cm.create(frame).reshape(18,18), columns = frame.symbols, index=frame.symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: How would you combine these descriptors from atom-level to become molecule-level?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now go back to cell 5 (STOP!) and see how your answers change for other configurations. The chair configuration is in traj[0], twist-boat in traj[400], boat in traj[800], half-chair in traj[1200], and planar in traj[1600]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A small dive into SOAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For computing symmetrized representations, there are many, *many* different software packages that offer different benefits.\n",
    "\n",
    "- [dscribe](https://singroup.github.io/dscribe/) is very user-friendly if you want to use off-the-shelf SOAP PowerSpectra (but that's about all that's available here).\n",
    "- [librascal](https://github.com/lab-cosmo/librascal) is a power package for every variation of SOAP, Behler-Parinello symmetry functions, and other atom-centered representations. Unfortunately, its development has been discontinued since 2022, so proceed with caution.\n",
    "- [rascaline](https://github.com/luthaf/rascaline) is another power package for every variation of SOAP, Behler-Parinello symmetry functions, and other atom-centered representations, but requires knowledge of the [equistore](https://github.com/lab-cosmo/equistore) format and has a steep learning curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We're going to proceed cautiously with rascaline, but I encourage everyone to ask ample questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In symmetrized descriptors, we have _hyperparameters_ that we can tune to mimic the physics of our system. In a 2-body SOAP descriptor, we tune:\n",
    "\n",
    "- the `atomic_gaussian_width`, how large of a Gaussian we'd like to place on each atom, in Angstrom\n",
    "- the `cutoff`, how far away from each atom we'd like to integrate\n",
    "- the `radial_basis`, what set of [basis functions](https://chem.libretexts.org/Courses/Pacific_Union_College/Quantum_Chemistry/11%3A_Computational_Quantum_Chemistry/11.02%3A_Gaussian_Basis_Sets) to use for radial expansion\n",
    "- the `max_radial` number of these basis functions to use\n",
    "- the `cutoff_function` that we use to weight neighbors (this makes it so that atoms far away from our \"central\" one are weighted less)\n",
    "\n",
    "Here are some good starting parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rascaline.calculators import SoapRadialSpectrum\n",
    "representation = SoapRadialSpectrum(\n",
    "    **{\n",
    "        \"atomic_gaussian_width\": 0.3,\n",
    "        \"max_radial\": 6,\n",
    "        \"cutoff\": 3.5,\n",
    "        \"radial_basis\": {\"Gto\": {}},\n",
    "        \"cutoff_function\": {\"ShiftedCosine\": {\"width\": 0.8}},\n",
    "        \"center_atom_weight\": 1.0,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = representation.compute(frame)\n",
    "\n",
    "# These two steps help with the equistore format\n",
    "rep = rep.keys_to_samples('species_center')\n",
    "rep = rep.keys_to_properties([\"species_neighbor\"])\n",
    "x = rep.block().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(x, index=frame.symbols, columns=['{}-neighbor, n={}'.format(\"CH\"[i//6], i%6) for i in range(12)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every neighboring species, we have a histogram across radial bases of where they fall!\n",
    "\n",
    "But this is *VERY* hard to read in chart form, let's look at a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x)\n",
    "plt.gca().set_yticks(np.arange(len(frame)))\n",
    "plt.gca().set_yticklabels(frame.symbols)\n",
    "plt.gca().set_ylabel(\"Focal atom\")\n",
    "\n",
    "plt.gca().set_xticks(np.arange(len(x[0])))\n",
    "plt.gca().set_xticklabels(['{}'.format(i%6) for i in range(12)])\n",
    "plt.gca().set_xlabel(\"n\")\n",
    "\n",
    "plt.annotate(\"C-Neighbors\",\n",
    "            xy=(0.25, 1), xycoords='axes fraction',\n",
    "            size=12, va=\"bottom\", ha=\"center\",)\n",
    "\n",
    "plt.annotate(\"H-Neighbors\",\n",
    "            xy=(0.75, 1), xycoords='axes fraction',\n",
    "            size=12, va=\"bottom\", ha=\"center\",)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you get to this point, turn to your neighbors to discuss. If you need something to do while you wait, this is a good, albeit lengthy read:\n",
    "    \n",
    "https://doi.org/10.1021/acs.chemrev.1c00021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But physics rarely relies on solely pair terms (at least good physics...)\n",
    "\n",
    "When we go to higher body-orders, we also histogram over angular components through spherical harmonics. So we specify\n",
    "\n",
    "- the `max_angular` number of spherical harmonics we expand over\n",
    "\n",
    "The PowerSpectrum is a three-body descriptor, where we check two neighbors for each focal atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rascaline.calculators import SoapPowerSpectrum\n",
    "representation = SoapPowerSpectrum(\n",
    "    **{\n",
    "        \"atomic_gaussian_width\": 0.3,\n",
    "        \"max_angular\": 4,\n",
    "        \"max_radial\": 6,\n",
    "        \"cutoff\": 3.5,\n",
    "        \"radial_basis\": {\"Gto\": {}},\n",
    "        \"cutoff_function\": {\"ShiftedCosine\": {\"width\": 0.8}},\n",
    "        \"center_atom_weight\": 1.0,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = representation.compute(frame)\n",
    "\n",
    "rep = rep.keys_to_samples('species_center')\n",
    "\n",
    "# There are two neighbor species now! \n",
    "rep = rep.keys_to_properties([\"species_neighbor_1\", \"species_neighbor_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rep.block().values.T)\n",
    "\n",
    "plt.gca().set_xticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a PCA, we can see that carbons are all very similar, but we have two types of hydrogens: in-plane and out-of-plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2).fit(x)\n",
    "t = pca.transform(x)\n",
    "\n",
    "chemiscope.show([frame], properties={\"t\": t}, environments=[(0, i, 3.5) for i in range(len(frame))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Okay! I want to make SOAP descriptors like you did for the activities before. How do I do that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we're only going to select carbon atoms as our focal atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from equistore import Labels\n",
    "\n",
    "values = []\n",
    "for i, _ in enumerate(traj):\n",
    "    for j in range(6): # carbons are indices 0-6\n",
    "        values.append([i,j])\n",
    "\n",
    "selection = Labels(\n",
    "    names=[\"structure\", \"center\"],\n",
    "    values=np.array(values),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = representation.compute(traj, selected_samples=selection)\n",
    "\n",
    "rep = rep.keys_to_samples('species_center')\n",
    "rep = rep.keys_to_properties([\"species_neighbor_1\", \"species_neighbor_2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to [standardize](https://scikit-matter.readthedocs.io/en/latest/examples/pcovr/PCovR_Scaling.html#sphx-glr-examples-pcovr-pcovr-scaling-py) our descriptors. Here we scale them all together, because their relative magnitude matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmatter.preprocessing import StandardFlexibleScaler\n",
    "x = StandardFlexibleScaler(column_wise=False).fit_transform(rep.block().values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, we'll split them by frame to help with later operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_soaps = np.array(np.split(x, len(traj)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Et voila! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(split_soaps - np.load('./datasets/cyclohexane/cyclohexane_descriptors.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "186.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

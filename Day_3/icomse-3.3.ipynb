{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves as an example of how to analyze a simulation trajectory using unsupervised techniques. Here, specifically, we'll be analyzing a simulation of cyclohexane conformations, simulated using quantum-espresso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this notebook, you will need to install:\n",
    "    \n",
    "- [ase](https://wiki.fysik.dtu.dk/ase/index.html)\n",
    "- [scikit-learn](https://scikit-learn.org/)\n",
    "- [scikit-matter](https://github.com/scikit-learn-contrib/scikit-matter)\n",
    "- [hdbscan](https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html)\n",
    "- [chemiscope](https://chemiscope.org)\n",
    "\n",
    "in addition to standard packages [numpy](https://numpy.org/) and [matplotlib](https://matplotlib.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Chemiscope widgets in Jupyter\n",
    "\n",
    "Please make sure you have jupyter extensions enabled.\n",
    "\n",
    "If at *any time* you are unable to load the chemiscope widgets in Jupyter, you can replace `chemiscope.show(` with `chemiscope.write_input('filename.json', ...` and upload the resulting file to [chemiscope.org](chemiscope.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ase skmatter chemiscope\n",
    "!git clone https://github.com/icomse/5th_workshop_MachineLearning.git\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from matplotlib import pyplot as plt\n",
    "import chemiscope\n",
    "import scipy\n",
    "from sklearn import cluster\n",
    "from sklearn import metrics\n",
    "import hdbscan\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "import os\n",
    "os.chdir('5th_workshop_MachineLearning/Day_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data\n",
    "\n",
    "Here we read in 5 MD trajectories and place them in a concatenated list `traj`.\n",
    "\n",
    "`ranges` is storing the range of `traj` corresponding to each original file.\n",
    "`conf_idx` is storing the location of the initial conformations.\n",
    "\n",
    "`rgb_colors` is the set of colors used for each conformer, stored in rgba format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the frames from each MD simulation\n",
    "traj = []\n",
    "names = [\"chair\", \"twist-boat\", \"boat\", \"half-chair\", \"planar\"]\n",
    "rgb_colors = [\n",
    "    (0.13333333333333333, 0.47058823529411764, 0.7098039215686275),\n",
    "    (0.4588235294117647, 0.7568627450980392, 0.34901960784313724),\n",
    "    (0.803921568627451, 0.6078431372549019, 0.16862745098039217),\n",
    "    (0.803921568627451, 0.13725490196078433, 0.15294117647058825),\n",
    "    (0.4392156862745098, 0.2784313725490196, 0.611764705882353),\n",
    "]\n",
    "\n",
    "ranges = np.zeros((len(names), 2), dtype=int)\n",
    "conf_idx = np.zeros(len(names), dtype=int)\n",
    "\n",
    "for i, n in enumerate(names):\n",
    "    frames = read(f\"./datasets/cyclohexane/{n}.xyz\",\":\",)\n",
    "\n",
    "    ranges[i] = (len(traj), len(traj) + len(frames))\n",
    "    conf_idx[i] = len(traj)\n",
    "    traj = [*traj, *frames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# energies of the simulation frames, relative to the chair conformation\n",
    "energy = np.array([a.info[\"relative_energy_eV\"] for a in traj])\n",
    "\n",
    "# energies of the known conformers, relative to the chair conformation\n",
    "c_energy = np.array([traj[c].info[\"relative_energy_eV\"] for c in conf_idx])\n",
    "\n",
    "# extrema for the energies\n",
    "max_e = max(energy)\n",
    "min_e = min(energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can confirm what our analysis will tell us: \n",
    "\n",
    "- the simulation starting in the planar conformation transitions to the chair conformation\n",
    "- the simulations starting in the twist-boat, boat, and half-chair conformations ultimately get stuck in the twist formation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(6, 4))\n",
    "\n",
    "for n, c, r, rgb in zip(names, c_energy, ranges, rgb_colors):\n",
    "    ax.plot(\n",
    "        range(0, r[1] - r[0]), energy[r[0] : r[1]] - min_e, label=n, c=rgb, zorder=-1\n",
    "    )\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Simulation Timestep\")\n",
    "ax.set_ylabel(\"Energy\")\n",
    "\n",
    "ax.set_xlim([0, len(energy) // 5])\n",
    "ax.set_ylim([-0.1, 1.25 * (max_e - min_e)])\n",
    "ax.set_yticklabels([])\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('figures/Figure5/energy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load descriptors \n",
    "We will use some precomputed geometric descriptors -- more on this this afternoon!\n",
    "\n",
    "Here's what you need to know.\n",
    "\n",
    "`atomic_desc` is `5000 x 6 x q` tensor, where `q` is the number of descriptors we have.\n",
    "\n",
    "For each frame, we have one descriptor per carbon atom (hence the 6!).\n",
    "\n",
    "We'll average this per-molecule into the variable `desc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_desc = np.load(\"./datasets/cyclohexane/cyclohexane_descriptors.npy\")\n",
    "\n",
    "X = np.mean(atomic_desc, axis=1)\n",
    "atomic_desc.shape, X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the colormap\n",
    "Here we are going to color each of our points based upon their similar to the initial conformers (which has been pre-computed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_config = np.array([frame.info[\"closest_conformer\"] for frame in traj])\n",
    "correct_labels = np.array([names.index(c) for c in closest_config])\n",
    "colors = np.array([frame.info[\"color\"] for frame in traj])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our t-sne from the previous notebook to perform clustering on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from openTSNE import TSNE\n",
    "\n",
    "# 0.9999 tells us here to keep 99.99% of the variance\n",
    "pca = PCA(n_components=0.999)\n",
    "pca.fit(X)\n",
    "\n",
    "pca_desc = pca.transform(X)\n",
    "\n",
    "n_neighbors_TSNE = 6\n",
    "\n",
    "tsne = TSNE(\n",
    "    n_components=2,  # number of components to project across\n",
    "    perplexity=n_neighbors_TSNE,  # amount of neighbors one point is posited to have... play around with this!\n",
    "    n_jobs=2,  # parallelization\n",
    "    random_state=42,\n",
    "    verbose=False,\n",
    ")\n",
    "T = tsne.fit(pca_desc)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(T[:, 0], T[:, 1], color=colors)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's make a plotting utility to help ourselves in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne_with_labels(labels, cutoff=10, fig=None, ax=None):\n",
    "    \n",
    "    all_colors = [\n",
    "        \"#ebac23\",\n",
    "        \"#b80058\",\n",
    "        \"#008cf9\",\n",
    "        \"#006e00\",\n",
    "        \"#00bbad\",\n",
    "        \"#d163e6\",\n",
    "        \"#b24502\",\n",
    "        \"#ff9287\",\n",
    "        \"#5954d6\",\n",
    "        \"#00c6f8\",\n",
    "        \"#878500\",\n",
    "    ]\n",
    "    \n",
    "    counts = np.array([labels.tolist().count(l) for l in list(sorted(set(labels)))])\n",
    "    colors = [\"none\" for _ in counts]\n",
    "\n",
    "    for i in range(1, len(counts) + 1):\n",
    "        if np.sort(counts)[-i] >= cutoff:\n",
    "            if i<len(all_colors):\n",
    "                colors[np.argsort(counts)[-i]] = all_colors[i]\n",
    "            else:\n",
    "                colors[np.argsort(counts)[-i]] = \"orange\"\n",
    "        \n",
    "    if fig is None or ax is None:\n",
    "        fig, ax = plt.subplots(1, figsize=(8, 8))\n",
    "    ax.scatter(T[:, 0], T[:, 1], c=\"k\", alpha=0.1, marker=\".\")\n",
    "    ax.scatter(\n",
    "        T[:, 0],\n",
    "        T[:, 1],\n",
    "        fc=\"none\",\n",
    "        ec=[colors[l] for l in labels],\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "    \n",
    "    ax.set_xlabel(r\"$t-SNE_1$\")\n",
    "    ax.set_ylabel(r\"$t-SNE_2$\")\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are our correct labels!\n",
    "\n",
    "plot_tsne_with_labels(correct_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the parameters of K-Means to get an appropriate clustering\n",
    "\n",
    "km = cluster.KMeans(\n",
    "    # ...\n",
    "    )\n",
    "km.fit(T)\n",
    "\n",
    "plot_tsne_with_labels(km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemiscope.show(\n",
    "    traj,\n",
    "    properties={\n",
    "        \"t\": T,\n",
    "        \"Relative Energy [eV]\": energy,\n",
    "        \"Closest Conformer\": closest_config,\n",
    "        \"Cluster\": km.labels_,\n",
    "        \"Correct Cluster\": correct_labels,\n",
    "    },\n",
    "    settings={\n",
    "        \"map\": {\n",
    "            \"symbol\": \"Closest Conformer\",\n",
    "            \"color\": {\"property\": \"Relative Energy [eV]\"},\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a few other clustering methods to try out:\n",
    "\n",
    "[Agglomerative Clustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering): `cluster.AgglomerativeClustering(n_clusters = int, affinity = sklearn.metrics.pairwise_distances`\n",
    "- You can also use sklearn to make a dendrogram of the clustering hierarchy! [Instructions here](https://scikit-learn.org/stable/auto_examples/cluster/plot_agglomerative_dendrogram.html#sphx-glr-auto-examples-cluster-plot-agglomerative-dendrogram-py)\n",
    "\n",
    "[DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html): `cluster.DBSCAN(eps = float, min_samples=int, metric=sklearn.metrics.pairwise_distance)`\n",
    "- eps is the size of the radius from each point\n",
    "- min_samples is the unmber of samples in a neighborhood for the algorithm to care about that cluster\n",
    "\n",
    "[HDBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.HDBSCAN.html#sklearn.cluster.HDBSCAN): `cluster.HDBSCAN(min_cluster_size=int, metric=sklearn.metrics.pairwise_distance)`\n",
    "\n",
    "[Mean Shift](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MeanShift.html#sklearn.cluster.MeanShift): `cluster.MeanShift()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and place their results in a dictionary like this:\n",
    "\n",
    "``` python\n",
    "    cluster_results = {\n",
    "                       \"technique_name_1\": list of labels,\n",
    "                       \"technique_name_2\": list of labels,\n",
    "                       \"technique_name_3\": list of labels,\n",
    "                      }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results = {\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_to_try = {\n",
    "    \"Rand\": lambda labels: metrics.rand_score(\n",
    "        labels_true=correct_labels, labels_pred=labels\n",
    "    ),\n",
    "    \"Jaccard\": lambda labels: metrics.jaccard_score(\n",
    "        y_true=correct_labels, y_pred=labels, average='macro',\n",
    "    ),\n",
    "    \"Fowlkes-Mallows\": lambda labels: metrics.fowlkes_mallows_score(\n",
    "        labels_true=correct_labels, labels_pred=labels\n",
    "    ),\n",
    "    \"F indicator\": lambda labels: metrics.f1_score(\n",
    "        y_true=correct_labels, y_pred=labels, average='macro',\n",
    "    ),\n",
    "    \"Silhouette\": partial(metrics.silhouette_score, X=T),\n",
    "    \"Davies-Bouldin\": partial(metrics.davies_bouldin_score, X=T),\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    1, len(cluster_results.keys())+1, figsize=(4 * len(cluster_results.keys())+4, 4)\n",
    ")\n",
    "plot_tsne_with_labels(correct_labels, ax=axes[0], fig=fig)\n",
    "for (key, value), ax in zip(cluster_results.items(), axes[1:]):\n",
    "    plot_tsne_with_labels(value, ax=ax, fig=fig)\n",
    "    ax.set_title(key)\n",
    "plt.show()\n",
    "\n",
    "scores = np.array(\n",
    "    [\n",
    "        [v(labels=labels) for v in scores_to_try.values()]\n",
    "        for labels in cluster_results.values()\n",
    "    ]\n",
    ")\n",
    "\n",
    "pd.DataFrame(scores, columns=scores_to_try.keys(), index=cluster_results.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discuss with the students next to you the pros and cons of each clustering technique!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "186.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
